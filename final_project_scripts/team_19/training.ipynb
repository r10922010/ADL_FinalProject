{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c42402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import jsonlines\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    BlenderbotTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddee88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './training_data.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b129ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with jsonlines.open(train_path) as f:\n",
    "    for i, line in enumerate(f.iter()):\n",
    "        train_data.append(line)\n",
    "# val_data = []\n",
    "# with jsonlines.open(val_path) as f:\n",
    "#     for line in f.iter():\n",
    "#         val_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0595d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname).to(device)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c16cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    encode_examples = {}\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for doc in examples:\n",
    "        inputs.append(doc['source'])\n",
    "        targets.append(doc['target'])\n",
    "            \n",
    "    # inputs = [doc[\"maintext\"] for doc in examples]\n",
    "    encode_examples  = tokenizer(inputs, max_length=120, truncation=True, padding=True)\n",
    "    encode_examples['target'] = tokenizer(targets, max_length=100, truncation=True, padding=True)\n",
    "    return encode_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc2ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_set = preprocess_function(train_data)\n",
    "#tokenized_summerize['validation'] = preprocess_function(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df17f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47710\n",
      "47710\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_set['target']['input_ids']))\n",
    "print(len(tokenized_set['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4e2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dialog(Dataset):\n",
    "    def __init__(self, encoded_dataset):\n",
    "        self.token = encoded_dataset['input_ids']\n",
    "        self.label = encoded_dataset['target']['input_ids'] if 'target' in encoded_dataset.keys() else None\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is None:\n",
    "            return torch.tensor(self.token[index])\n",
    "        else:\n",
    "            return torch.tensor(self.token[index]), torch.tensor(self.label[index])\n",
    "    def __len__(self):\n",
    "        return len(self.token)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4c9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dialog(tokenized_set)\n",
    "#valset = Dialog(tokenized_summerize['validation'])\n",
    "trainloader = DataLoader(dataset = trainset, batch_size = 64, shuffle = True)\n",
    "#valloader = DataLoader(dataset = valset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce37b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    #torch.save(model.state_dict(), checkpoint_path)\n",
    "    model.save_pretrained(checkpoint_path)\n",
    "    tokenizer.save_pretrained(checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    model = torch.load(checkpoint_path)\n",
    "    #model.load_state_dict(state['state_dict'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab3328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(model, epoch, save_interval, log_interval=100):\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=1e-4, betas=(0.9, 0.999),weight_decay=0)\n",
    "    model.train()  # set training mode\n",
    "    best = 0    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        loss_sum = 0\n",
    "        for batch_idx, (input_ids, labels) in enumerate(trainloader):\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_ids=input_ids,labels=labels)\n",
    "            loss = output.loss\n",
    "            loss_sum = loss_sum + loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(input_ids), len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                # test(model)\n",
    "                if iteration>500:\n",
    "                    save_checkpoint('./final-%i/' % iteration, model, optimizer)    \n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "        print('\\nTrain set:Loss: ({:.0f})\\n'.format(loss_sum / len(trainloader)))\n",
    "        \n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('./final-%i/' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb73bc66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/47710 (0%)]\tLoss: 14.282977\n",
      "Train Epoch: 0 [6400/47710 (13%)]\tLoss: 0.420515\n",
      "Train Epoch: 0 [12800/47710 (27%)]\tLoss: 0.405770\n",
      "Train Epoch: 0 [19200/47710 (40%)]\tLoss: 0.398374\n",
      "Train Epoch: 0 [25600/47710 (54%)]\tLoss: 0.368005\n",
      "Train Epoch: 0 [32000/47710 (67%)]\tLoss: 0.373839\n",
      "Train Epoch: 0 [38400/47710 (80%)]\tLoss: 0.361223\n",
      "Train Epoch: 0 [44800/47710 (94%)]\tLoss: 0.406293\n",
      "\n",
      "Train set:Loss: (1)\n",
      "\n",
      "Train Epoch: 1 [3456/47710 (7%)]\tLoss: 0.318846\n",
      "Train Epoch: 1 [9856/47710 (21%)]\tLoss: 0.311986\n",
      "Train Epoch: 1 [16256/47710 (34%)]\tLoss: 0.331908\n",
      "model saved to ./final-1000/\n",
      "Train Epoch: 1 [22656/47710 (47%)]\tLoss: 0.308420\n",
      "Train Epoch: 1 [29056/47710 (61%)]\tLoss: 0.317582\n",
      "Train Epoch: 1 [35456/47710 (74%)]\tLoss: 0.342214\n",
      "Train Epoch: 1 [41856/47710 (88%)]\tLoss: 0.296771\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 2 [512/47710 (1%)]\tLoss: 0.218342\n",
      "Train Epoch: 2 [6912/47710 (14%)]\tLoss: 0.181810\n",
      "Train Epoch: 2 [13312/47710 (28%)]\tLoss: 0.233637\n",
      "Train Epoch: 2 [19712/47710 (41%)]\tLoss: 0.259729\n",
      "Train Epoch: 2 [26112/47710 (55%)]\tLoss: 0.188863\n",
      "Train Epoch: 2 [32512/47710 (68%)]\tLoss: 0.224319\n",
      "model saved to ./final-2000/\n",
      "Train Epoch: 2 [38912/47710 (82%)]\tLoss: 0.190589\n",
      "Train Epoch: 2 [45312/47710 (95%)]\tLoss: 0.230651\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 3 [3968/47710 (8%)]\tLoss: 0.139161\n",
      "Train Epoch: 3 [10368/47710 (22%)]\tLoss: 0.155911\n",
      "Train Epoch: 3 [16768/47710 (35%)]\tLoss: 0.164223\n",
      "Train Epoch: 3 [23168/47710 (49%)]\tLoss: 0.139458\n",
      "Train Epoch: 3 [29568/47710 (62%)]\tLoss: 0.126110\n",
      "Train Epoch: 3 [35968/47710 (75%)]\tLoss: 0.179312\n",
      "Train Epoch: 3 [42368/47710 (89%)]\tLoss: 0.130806\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 4 [1024/47710 (2%)]\tLoss: 0.098944\n",
      "model saved to ./final-3000/\n",
      "Train Epoch: 4 [7424/47710 (16%)]\tLoss: 0.105377\n",
      "Train Epoch: 4 [13824/47710 (29%)]\tLoss: 0.106213\n",
      "Train Epoch: 4 [20224/47710 (42%)]\tLoss: 0.112671\n",
      "Train Epoch: 4 [26624/47710 (56%)]\tLoss: 0.106478\n",
      "Train Epoch: 4 [33024/47710 (69%)]\tLoss: 0.125960\n",
      "Train Epoch: 4 [39424/47710 (83%)]\tLoss: 0.135925\n",
      "Train Epoch: 4 [45824/47710 (96%)]\tLoss: 0.105597\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 5 [4480/47710 (9%)]\tLoss: 0.066047\n",
      "Train Epoch: 5 [10880/47710 (23%)]\tLoss: 0.072304\n",
      "Train Epoch: 5 [17280/47710 (36%)]\tLoss: 0.076578\n",
      "model saved to ./final-4000/\n",
      "Train Epoch: 5 [23680/47710 (50%)]\tLoss: 0.087862\n",
      "Train Epoch: 5 [30080/47710 (63%)]\tLoss: 0.084428\n",
      "Train Epoch: 5 [36480/47710 (76%)]\tLoss: 0.079428\n",
      "Train Epoch: 5 [42880/47710 (90%)]\tLoss: 0.102555\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 6 [1536/47710 (3%)]\tLoss: 0.069922\n",
      "Train Epoch: 6 [7936/47710 (17%)]\tLoss: 0.072317\n",
      "Train Epoch: 6 [14336/47710 (30%)]\tLoss: 0.066347\n",
      "Train Epoch: 6 [20736/47710 (43%)]\tLoss: 0.065941\n",
      "Train Epoch: 6 [27136/47710 (57%)]\tLoss: 0.066167\n",
      "Train Epoch: 6 [33536/47710 (70%)]\tLoss: 0.072060\n",
      "model saved to ./final-5000/\n",
      "Train Epoch: 6 [39936/47710 (84%)]\tLoss: 0.076499\n",
      "Train Epoch: 6 [46336/47710 (97%)]\tLoss: 0.084510\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 7 [4992/47710 (10%)]\tLoss: 0.059319\n",
      "Train Epoch: 7 [11392/47710 (24%)]\tLoss: 0.060524\n",
      "Train Epoch: 7 [17792/47710 (37%)]\tLoss: 0.053790\n",
      "Train Epoch: 7 [24192/47710 (51%)]\tLoss: 0.066092\n",
      "Train Epoch: 7 [30592/47710 (64%)]\tLoss: 0.062371\n",
      "Train Epoch: 7 [36992/47710 (77%)]\tLoss: 0.054357\n",
      "Train Epoch: 7 [43392/47710 (91%)]\tLoss: 0.067524\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 8 [2048/47710 (4%)]\tLoss: 0.047816\n",
      "model saved to ./final-6000/\n",
      "Train Epoch: 8 [8448/47710 (18%)]\tLoss: 0.043320\n",
      "Train Epoch: 8 [14848/47710 (31%)]\tLoss: 0.055431\n",
      "Train Epoch: 8 [21248/47710 (45%)]\tLoss: 0.054181\n",
      "Train Epoch: 8 [27648/47710 (58%)]\tLoss: 0.051128\n",
      "Train Epoch: 8 [34048/47710 (71%)]\tLoss: 0.053612\n",
      "Train Epoch: 8 [40448/47710 (85%)]\tLoss: 0.060841\n",
      "Train Epoch: 8 [46848/47710 (98%)]\tLoss: 0.061528\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 9 [5504/47710 (12%)]\tLoss: 0.043987\n",
      "Train Epoch: 9 [11904/47710 (25%)]\tLoss: 0.042209\n",
      "Train Epoch: 9 [18304/47710 (38%)]\tLoss: 0.053016\n",
      "model saved to ./final-7000/\n",
      "Train Epoch: 9 [24704/47710 (52%)]\tLoss: 0.058390\n",
      "Train Epoch: 9 [31104/47710 (65%)]\tLoss: 0.055453\n",
      "Train Epoch: 9 [37504/47710 (79%)]\tLoss: 0.060962\n",
      "Train Epoch: 9 [43904/47710 (92%)]\tLoss: 0.054786\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 10 [2560/47710 (5%)]\tLoss: 0.037343\n",
      "Train Epoch: 10 [8960/47710 (19%)]\tLoss: 0.037926\n",
      "Train Epoch: 10 [15360/47710 (32%)]\tLoss: 0.045641\n",
      "Train Epoch: 10 [21760/47710 (46%)]\tLoss: 0.045425\n",
      "Train Epoch: 10 [28160/47710 (59%)]\tLoss: 0.048607\n",
      "Train Epoch: 10 [34560/47710 (72%)]\tLoss: 0.056744\n",
      "model saved to ./final-8000/\n",
      "Train Epoch: 10 [40960/47710 (86%)]\tLoss: 0.052225\n",
      "Train Epoch: 10 [47360/47710 (99%)]\tLoss: 0.050984\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 11 [6016/47710 (13%)]\tLoss: 0.047544\n",
      "Train Epoch: 11 [12416/47710 (26%)]\tLoss: 0.046476\n",
      "Train Epoch: 11 [18816/47710 (39%)]\tLoss: 0.043416\n",
      "Train Epoch: 11 [25216/47710 (53%)]\tLoss: 0.043243\n",
      "Train Epoch: 11 [31616/47710 (66%)]\tLoss: 0.049096\n",
      "Train Epoch: 11 [38016/47710 (80%)]\tLoss: 0.051754\n",
      "Train Epoch: 11 [44416/47710 (93%)]\tLoss: 0.050809\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 12 [3072/47710 (6%)]\tLoss: 0.038848\n",
      "model saved to ./final-9000/\n",
      "Train Epoch: 12 [9472/47710 (20%)]\tLoss: 0.040929\n",
      "Train Epoch: 12 [15872/47710 (33%)]\tLoss: 0.044094\n",
      "Train Epoch: 12 [22272/47710 (47%)]\tLoss: 0.052743\n",
      "Train Epoch: 12 [28672/47710 (60%)]\tLoss: 0.046985\n",
      "Train Epoch: 12 [35072/47710 (73%)]\tLoss: 0.039187\n",
      "Train Epoch: 12 [41472/47710 (87%)]\tLoss: 0.044780\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 13 [128/47710 (0%)]\tLoss: 0.035461\n",
      "Train Epoch: 13 [6528/47710 (14%)]\tLoss: 0.034455\n",
      "Train Epoch: 13 [12928/47710 (27%)]\tLoss: 0.037781\n",
      "Train Epoch: 13 [19328/47710 (40%)]\tLoss: 0.036370\n",
      "model saved to ./final-10000/\n",
      "Train Epoch: 13 [25728/47710 (54%)]\tLoss: 0.041002\n",
      "Train Epoch: 13 [32128/47710 (67%)]\tLoss: 0.040923\n",
      "Train Epoch: 13 [38528/47710 (81%)]\tLoss: 0.043162\n",
      "Train Epoch: 13 [44928/47710 (94%)]\tLoss: 0.047350\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 14 [3584/47710 (8%)]\tLoss: 0.034104\n",
      "Train Epoch: 14 [9984/47710 (21%)]\tLoss: 0.036227\n",
      "Train Epoch: 14 [16384/47710 (34%)]\tLoss: 0.042149\n",
      "Train Epoch: 14 [22784/47710 (48%)]\tLoss: 0.038460\n",
      "Train Epoch: 14 [29184/47710 (61%)]\tLoss: 0.049109\n",
      "Train Epoch: 14 [35584/47710 (75%)]\tLoss: 0.052105\n",
      "model saved to ./final-11000/\n",
      "Train Epoch: 14 [41984/47710 (88%)]\tLoss: 0.048486\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 15 [640/47710 (1%)]\tLoss: 0.032301\n",
      "Train Epoch: 15 [7040/47710 (15%)]\tLoss: 0.036304\n",
      "Train Epoch: 15 [13440/47710 (28%)]\tLoss: 0.045529\n",
      "Train Epoch: 15 [19840/47710 (42%)]\tLoss: 0.039533\n",
      "Train Epoch: 15 [26240/47710 (55%)]\tLoss: 0.038791\n",
      "Train Epoch: 15 [32640/47710 (68%)]\tLoss: 0.043834\n",
      "Train Epoch: 15 [39040/47710 (82%)]\tLoss: 0.043613\n",
      "Train Epoch: 15 [45440/47710 (95%)]\tLoss: 0.038895\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 16 [4096/47710 (9%)]\tLoss: 0.026833\n",
      "model saved to ./final-12000/\n",
      "Train Epoch: 16 [10496/47710 (22%)]\tLoss: 0.032670\n",
      "Train Epoch: 16 [16896/47710 (35%)]\tLoss: 0.035176\n",
      "Train Epoch: 16 [23296/47710 (49%)]\tLoss: 0.041540\n",
      "Train Epoch: 16 [29696/47710 (62%)]\tLoss: 0.040031\n",
      "Train Epoch: 16 [36096/47710 (76%)]\tLoss: 0.043486\n",
      "Train Epoch: 16 [42496/47710 (89%)]\tLoss: 0.051065\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 17 [1152/47710 (2%)]\tLoss: 0.028380\n",
      "Train Epoch: 17 [7552/47710 (16%)]\tLoss: 0.031927\n",
      "Train Epoch: 17 [13952/47710 (29%)]\tLoss: 0.036971\n",
      "Train Epoch: 17 [20352/47710 (43%)]\tLoss: 0.038271\n",
      "model saved to ./final-13000/\n",
      "Train Epoch: 17 [26752/47710 (56%)]\tLoss: 0.041813\n",
      "Train Epoch: 17 [33152/47710 (69%)]\tLoss: 0.041266\n",
      "Train Epoch: 17 [39552/47710 (83%)]\tLoss: 0.043289\n",
      "Train Epoch: 17 [45952/47710 (96%)]\tLoss: 0.039667\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 18 [4608/47710 (10%)]\tLoss: 0.030663\n",
      "Train Epoch: 18 [11008/47710 (23%)]\tLoss: 0.036467\n",
      "Train Epoch: 18 [17408/47710 (36%)]\tLoss: 0.044257\n",
      "Train Epoch: 18 [23808/47710 (50%)]\tLoss: 0.038993\n",
      "Train Epoch: 18 [30208/47710 (63%)]\tLoss: 0.038290\n",
      "Train Epoch: 18 [36608/47710 (77%)]\tLoss: 0.044786\n",
      "model saved to ./final-14000/\n",
      "Train Epoch: 18 [43008/47710 (90%)]\tLoss: 0.037753\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 19 [1664/47710 (3%)]\tLoss: 0.032025\n",
      "Train Epoch: 19 [8064/47710 (17%)]\tLoss: 0.033029\n",
      "Train Epoch: 19 [14464/47710 (30%)]\tLoss: 0.031824\n",
      "Train Epoch: 19 [20864/47710 (44%)]\tLoss: 0.034195\n",
      "Train Epoch: 19 [27264/47710 (57%)]\tLoss: 0.033666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [33664/47710 (71%)]\tLoss: 0.037287\n",
      "Train Epoch: 19 [40064/47710 (84%)]\tLoss: 0.042731\n",
      "Train Epoch: 19 [46464/47710 (97%)]\tLoss: 0.039081\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 20 [5120/47710 (11%)]\tLoss: 0.029406\n",
      "model saved to ./final-15000/\n",
      "Train Epoch: 20 [11520/47710 (24%)]\tLoss: 0.030041\n",
      "Train Epoch: 20 [17920/47710 (38%)]\tLoss: 0.042536\n",
      "Train Epoch: 20 [24320/47710 (51%)]\tLoss: 0.039930\n",
      "Train Epoch: 20 [30720/47710 (64%)]\tLoss: 0.035395\n",
      "Train Epoch: 20 [37120/47710 (78%)]\tLoss: 0.033573\n",
      "Train Epoch: 20 [43520/47710 (91%)]\tLoss: 0.040621\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 21 [2176/47710 (5%)]\tLoss: 0.037661\n",
      "Train Epoch: 21 [8576/47710 (18%)]\tLoss: 0.033158\n",
      "Train Epoch: 21 [14976/47710 (31%)]\tLoss: 0.034601\n",
      "Train Epoch: 21 [21376/47710 (45%)]\tLoss: 0.034011\n",
      "model saved to ./final-16000/\n",
      "Train Epoch: 21 [27776/47710 (58%)]\tLoss: 0.037552\n",
      "Train Epoch: 21 [34176/47710 (72%)]\tLoss: 0.037831\n",
      "Train Epoch: 21 [40576/47710 (85%)]\tLoss: 0.041770\n",
      "Train Epoch: 21 [46976/47710 (98%)]\tLoss: 0.045380\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 22 [5632/47710 (12%)]\tLoss: 0.031901\n",
      "Train Epoch: 22 [12032/47710 (25%)]\tLoss: 0.036082\n",
      "Train Epoch: 22 [18432/47710 (39%)]\tLoss: 0.034003\n",
      "Train Epoch: 22 [24832/47710 (52%)]\tLoss: 0.037487\n",
      "Train Epoch: 22 [31232/47710 (65%)]\tLoss: 0.040793\n",
      "Train Epoch: 22 [37632/47710 (79%)]\tLoss: 0.035051\n",
      "model saved to ./final-17000/\n",
      "Train Epoch: 22 [44032/47710 (92%)]\tLoss: 0.033767\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 23 [2688/47710 (6%)]\tLoss: 0.033524\n",
      "Train Epoch: 23 [9088/47710 (19%)]\tLoss: 0.033436\n",
      "Train Epoch: 23 [15488/47710 (32%)]\tLoss: 0.032116\n",
      "Train Epoch: 23 [21888/47710 (46%)]\tLoss: 0.032071\n",
      "Train Epoch: 23 [28288/47710 (59%)]\tLoss: 0.035887\n",
      "Train Epoch: 23 [34688/47710 (73%)]\tLoss: 0.039284\n",
      "Train Epoch: 23 [41088/47710 (86%)]\tLoss: 0.035949\n",
      "Train Epoch: 23 [47488/47710 (99%)]\tLoss: 0.041248\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 24 [6144/47710 (13%)]\tLoss: 0.025894\n",
      "model saved to ./final-18000/\n",
      "Train Epoch: 24 [12544/47710 (26%)]\tLoss: 0.030963\n",
      "Train Epoch: 24 [18944/47710 (40%)]\tLoss: 0.030111\n",
      "Train Epoch: 24 [25344/47710 (53%)]\tLoss: 0.029446\n",
      "Train Epoch: 24 [31744/47710 (66%)]\tLoss: 0.038284\n",
      "Train Epoch: 24 [38144/47710 (80%)]\tLoss: 0.034173\n",
      "Train Epoch: 24 [44544/47710 (93%)]\tLoss: 0.043553\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 25 [3200/47710 (7%)]\tLoss: 0.025177\n",
      "Train Epoch: 25 [9600/47710 (20%)]\tLoss: 0.028789\n",
      "Train Epoch: 25 [16000/47710 (34%)]\tLoss: 0.034607\n",
      "Train Epoch: 25 [22400/47710 (47%)]\tLoss: 0.033023\n",
      "model saved to ./final-19000/\n",
      "Train Epoch: 25 [28800/47710 (60%)]\tLoss: 0.038279\n",
      "Train Epoch: 25 [35200/47710 (74%)]\tLoss: 0.034160\n",
      "Train Epoch: 25 [41600/47710 (87%)]\tLoss: 0.033403\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 26 [256/47710 (1%)]\tLoss: 0.025354\n",
      "Train Epoch: 26 [6656/47710 (14%)]\tLoss: 0.027838\n",
      "Train Epoch: 26 [13056/47710 (27%)]\tLoss: 0.026639\n",
      "Train Epoch: 26 [19456/47710 (41%)]\tLoss: 0.033646\n",
      "Train Epoch: 26 [25856/47710 (54%)]\tLoss: 0.032803\n",
      "Train Epoch: 26 [32256/47710 (68%)]\tLoss: 0.034495\n",
      "Train Epoch: 26 [38656/47710 (81%)]\tLoss: 0.036741\n",
      "model saved to ./final-20000/\n",
      "Train Epoch: 26 [45056/47710 (94%)]\tLoss: 0.035968\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 27 [3712/47710 (8%)]\tLoss: 0.026021\n",
      "Train Epoch: 27 [10112/47710 (21%)]\tLoss: 0.034760\n",
      "Train Epoch: 27 [16512/47710 (35%)]\tLoss: 0.028868\n",
      "Train Epoch: 27 [22912/47710 (48%)]\tLoss: 0.038117\n",
      "Train Epoch: 27 [29312/47710 (61%)]\tLoss: 0.030993\n",
      "Train Epoch: 27 [35712/47710 (75%)]\tLoss: 0.034546\n",
      "Train Epoch: 27 [42112/47710 (88%)]\tLoss: 0.031190\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 28 [768/47710 (2%)]\tLoss: 0.027862\n",
      "Train Epoch: 28 [7168/47710 (15%)]\tLoss: 0.031390\n",
      "model saved to ./final-21000/\n",
      "Train Epoch: 28 [13568/47710 (28%)]\tLoss: 0.030767\n",
      "Train Epoch: 28 [19968/47710 (42%)]\tLoss: 0.034740\n",
      "Train Epoch: 28 [26368/47710 (55%)]\tLoss: 0.031969\n",
      "Train Epoch: 28 [32768/47710 (69%)]\tLoss: 0.035007\n",
      "Train Epoch: 28 [39168/47710 (82%)]\tLoss: 0.033399\n",
      "Train Epoch: 28 [45568/47710 (95%)]\tLoss: 0.035072\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 29 [4224/47710 (9%)]\tLoss: 0.036078\n",
      "Train Epoch: 29 [10624/47710 (22%)]\tLoss: 0.032502\n",
      "Train Epoch: 29 [17024/47710 (36%)]\tLoss: 0.033481\n",
      "Train Epoch: 29 [23424/47710 (49%)]\tLoss: 0.023951\n",
      "model saved to ./final-22000/\n",
      "Train Epoch: 29 [29824/47710 (62%)]\tLoss: 0.035558\n",
      "Train Epoch: 29 [36224/47710 (76%)]\tLoss: 0.033472\n",
      "Train Epoch: 29 [42624/47710 (89%)]\tLoss: 0.034682\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 30 [1280/47710 (3%)]\tLoss: 0.025709\n",
      "Train Epoch: 30 [7680/47710 (16%)]\tLoss: 0.026790\n",
      "Train Epoch: 30 [14080/47710 (29%)]\tLoss: 0.035751\n",
      "Train Epoch: 30 [20480/47710 (43%)]\tLoss: 0.028238\n",
      "Train Epoch: 30 [26880/47710 (56%)]\tLoss: 0.036998\n",
      "Train Epoch: 30 [33280/47710 (70%)]\tLoss: 0.027779\n",
      "Train Epoch: 30 [39680/47710 (83%)]\tLoss: 0.032369\n",
      "model saved to ./final-23000/\n",
      "Train Epoch: 30 [46080/47710 (97%)]\tLoss: 0.038923\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 31 [4736/47710 (10%)]\tLoss: 0.029736\n",
      "Train Epoch: 31 [11136/47710 (23%)]\tLoss: 0.028787\n",
      "Train Epoch: 31 [17536/47710 (37%)]\tLoss: 0.034412\n",
      "Train Epoch: 31 [23936/47710 (50%)]\tLoss: 0.029142\n",
      "Train Epoch: 31 [30336/47710 (64%)]\tLoss: 0.037117\n",
      "Train Epoch: 31 [36736/47710 (77%)]\tLoss: 0.035371\n",
      "Train Epoch: 31 [43136/47710 (90%)]\tLoss: 0.033798\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 32 [1792/47710 (4%)]\tLoss: 0.026790\n",
      "Train Epoch: 32 [8192/47710 (17%)]\tLoss: 0.028905\n",
      "model saved to ./final-24000/\n",
      "Train Epoch: 32 [14592/47710 (31%)]\tLoss: 0.032163\n",
      "Train Epoch: 32 [20992/47710 (44%)]\tLoss: 0.031519\n",
      "Train Epoch: 32 [27392/47710 (57%)]\tLoss: 0.032247\n",
      "Train Epoch: 32 [33792/47710 (71%)]\tLoss: 0.032282\n",
      "Train Epoch: 32 [40192/47710 (84%)]\tLoss: 0.032579\n",
      "Train Epoch: 32 [46592/47710 (98%)]\tLoss: 0.033707\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 33 [5248/47710 (11%)]\tLoss: 0.024799\n",
      "Train Epoch: 33 [11648/47710 (24%)]\tLoss: 0.026902\n",
      "Train Epoch: 33 [18048/47710 (38%)]\tLoss: 0.032467\n",
      "Train Epoch: 33 [24448/47710 (51%)]\tLoss: 0.033434\n",
      "model saved to ./final-25000/\n",
      "Train Epoch: 33 [30848/47710 (65%)]\tLoss: 0.036088\n",
      "Train Epoch: 33 [37248/47710 (78%)]\tLoss: 0.035173\n",
      "Train Epoch: 33 [43648/47710 (91%)]\tLoss: 0.036495\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 34 [2304/47710 (5%)]\tLoss: 0.025657\n",
      "Train Epoch: 34 [8704/47710 (18%)]\tLoss: 0.026155\n",
      "Train Epoch: 34 [15104/47710 (32%)]\tLoss: 0.027655\n",
      "Train Epoch: 34 [21504/47710 (45%)]\tLoss: 0.032525\n",
      "Train Epoch: 34 [27904/47710 (58%)]\tLoss: 0.034095\n",
      "Train Epoch: 34 [34304/47710 (72%)]\tLoss: 0.030622\n",
      "Train Epoch: 34 [40704/47710 (85%)]\tLoss: 0.036847\n",
      "model saved to ./final-26000/\n",
      "Train Epoch: 34 [47104/47710 (99%)]\tLoss: 0.029226\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 35 [5760/47710 (12%)]\tLoss: 0.024085\n",
      "Train Epoch: 35 [12160/47710 (25%)]\tLoss: 0.032473\n",
      "Train Epoch: 35 [18560/47710 (39%)]\tLoss: 0.028556\n",
      "Train Epoch: 35 [24960/47710 (52%)]\tLoss: 0.030677\n",
      "Train Epoch: 35 [31360/47710 (66%)]\tLoss: 0.032566\n",
      "Train Epoch: 35 [37760/47710 (79%)]\tLoss: 0.037420\n",
      "Train Epoch: 35 [44160/47710 (92%)]\tLoss: 0.029769\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 36 [2816/47710 (6%)]\tLoss: 0.025838\n",
      "Train Epoch: 36 [9216/47710 (19%)]\tLoss: 0.028096\n",
      "model saved to ./final-27000/\n",
      "Train Epoch: 36 [15616/47710 (33%)]\tLoss: 0.026154\n",
      "Train Epoch: 36 [22016/47710 (46%)]\tLoss: 0.027618\n",
      "Train Epoch: 36 [28416/47710 (60%)]\tLoss: 0.030573\n",
      "Train Epoch: 36 [34816/47710 (73%)]\tLoss: 0.039183\n",
      "Train Epoch: 36 [41216/47710 (86%)]\tLoss: 0.034259\n",
      "Train Epoch: 36 [47616/47710 (100%)]\tLoss: 0.036200\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 37 [6272/47710 (13%)]\tLoss: 0.028054\n",
      "Train Epoch: 37 [12672/47710 (27%)]\tLoss: 0.028771\n",
      "Train Epoch: 37 [19072/47710 (40%)]\tLoss: 0.029864\n",
      "Train Epoch: 37 [25472/47710 (53%)]\tLoss: 0.031460\n",
      "model saved to ./final-28000/\n",
      "Train Epoch: 37 [31872/47710 (67%)]\tLoss: 0.031856\n",
      "Train Epoch: 37 [38272/47710 (80%)]\tLoss: 0.032071\n",
      "Train Epoch: 37 [44672/47710 (94%)]\tLoss: 0.035696\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 38 [3328/47710 (7%)]\tLoss: 0.028227\n",
      "Train Epoch: 38 [9728/47710 (20%)]\tLoss: 0.027971\n",
      "Train Epoch: 38 [16128/47710 (34%)]\tLoss: 0.028939\n",
      "Train Epoch: 38 [22528/47710 (47%)]\tLoss: 0.026973\n",
      "Train Epoch: 38 [28928/47710 (61%)]\tLoss: 0.033721\n",
      "Train Epoch: 38 [35328/47710 (74%)]\tLoss: 0.035863\n",
      "Train Epoch: 38 [41728/47710 (87%)]\tLoss: 0.034216\n",
      "model saved to ./final-29000/\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 39 [384/47710 (1%)]\tLoss: 0.027095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [6784/47710 (14%)]\tLoss: 0.029896\n",
      "Train Epoch: 39 [13184/47710 (28%)]\tLoss: 0.032103\n",
      "Train Epoch: 39 [19584/47710 (41%)]\tLoss: 0.029268\n",
      "Train Epoch: 39 [25984/47710 (54%)]\tLoss: 0.023883\n",
      "Train Epoch: 39 [32384/47710 (68%)]\tLoss: 0.027877\n",
      "Train Epoch: 39 [38784/47710 (81%)]\tLoss: 0.033551\n",
      "Train Epoch: 39 [45184/47710 (95%)]\tLoss: 0.036483\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 40 [3840/47710 (8%)]\tLoss: 0.024010\n",
      "Train Epoch: 40 [10240/47710 (21%)]\tLoss: 0.028815\n",
      "model saved to ./final-30000/\n",
      "Train Epoch: 40 [16640/47710 (35%)]\tLoss: 0.028798\n",
      "Train Epoch: 40 [23040/47710 (48%)]\tLoss: 0.032934\n",
      "Train Epoch: 40 [29440/47710 (62%)]\tLoss: 0.031326\n",
      "Train Epoch: 40 [35840/47710 (75%)]\tLoss: 0.034728\n",
      "Train Epoch: 40 [42240/47710 (88%)]\tLoss: 0.034432\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 41 [896/47710 (2%)]\tLoss: 0.029434\n",
      "Train Epoch: 41 [7296/47710 (15%)]\tLoss: 0.030007\n",
      "Train Epoch: 41 [13696/47710 (29%)]\tLoss: 0.022849\n",
      "Train Epoch: 41 [20096/47710 (42%)]\tLoss: 0.029001\n",
      "Train Epoch: 41 [26496/47710 (55%)]\tLoss: 0.031607\n",
      "model saved to ./final-31000/\n",
      "Train Epoch: 41 [32896/47710 (69%)]\tLoss: 0.036105\n",
      "Train Epoch: 41 [39296/47710 (82%)]\tLoss: 0.030323\n",
      "Train Epoch: 41 [45696/47710 (96%)]\tLoss: 0.032761\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 42 [4352/47710 (9%)]\tLoss: 0.023352\n",
      "Train Epoch: 42 [10752/47710 (23%)]\tLoss: 0.025873\n",
      "Train Epoch: 42 [17152/47710 (36%)]\tLoss: 0.024658\n",
      "Train Epoch: 42 [23552/47710 (49%)]\tLoss: 0.025360\n",
      "Train Epoch: 42 [29952/47710 (63%)]\tLoss: 0.029549\n",
      "Train Epoch: 42 [36352/47710 (76%)]\tLoss: 0.026532\n",
      "Train Epoch: 42 [42752/47710 (90%)]\tLoss: 0.030636\n",
      "model saved to ./final-32000/\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 43 [1408/47710 (3%)]\tLoss: 0.024937\n",
      "Train Epoch: 43 [7808/47710 (16%)]\tLoss: 0.025305\n",
      "Train Epoch: 43 [14208/47710 (30%)]\tLoss: 0.029003\n",
      "Train Epoch: 43 [20608/47710 (43%)]\tLoss: 0.026552\n",
      "Train Epoch: 43 [27008/47710 (57%)]\tLoss: 0.030437\n",
      "Train Epoch: 43 [33408/47710 (70%)]\tLoss: 0.028019\n",
      "Train Epoch: 43 [39808/47710 (83%)]\tLoss: 0.029568\n",
      "Train Epoch: 43 [46208/47710 (97%)]\tLoss: 0.036036\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "Train Epoch: 44 [4864/47710 (10%)]\tLoss: 0.028020\n",
      "Train Epoch: 44 [11264/47710 (24%)]\tLoss: 0.027165\n",
      "model saved to ./final-33000/\n",
      "Train Epoch: 44 [17664/47710 (37%)]\tLoss: 0.032492\n",
      "Train Epoch: 44 [24064/47710 (50%)]\tLoss: 0.026207\n",
      "Train Epoch: 44 [30464/47710 (64%)]\tLoss: 0.028712\n",
      "Train Epoch: 44 [36864/47710 (77%)]\tLoss: 0.029183\n",
      "Train Epoch: 44 [43264/47710 (91%)]\tLoss: 0.032054\n",
      "\n",
      "Train set:Loss: (0)\n",
      "\n",
      "model saved to ./final-33570/\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_save(model, epoch = 45, save_interval = 1000, log_interval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f3c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa882f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fa0578c3d0ab8305ee21e0a4f0a06849b2568e8436229705a3cd15e2e123ffa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
