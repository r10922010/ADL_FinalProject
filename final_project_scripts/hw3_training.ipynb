{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00268fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import jsonlines\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    BlenderbotTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b456eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './dataset.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with jsonlines.open(train_path) as f:\n",
    "    for line in f.iter():\n",
    "        train_data.append(line)\n",
    "# val_data = []\n",
    "# with jsonlines.open(val_path) as f:\n",
    "#     for line in f.iter():\n",
    "#         val_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dae39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname).to(device)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "\n",
    "\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916d779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     encode_examples = {}\n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "#     for doc in examples:\n",
    "#         for i, dialog in enumerate(doc['dialog']):\n",
    "#             if i%2 == 1:\n",
    "#                 inputs.append(dialog)\n",
    "#             else:\n",
    "#                 targets.append(dialog)\n",
    "#     # inputs = [doc[\"maintext\"] for doc in examples]\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     encode_examples = tokenizer(inputs, max_length=100, truncation=True, padding=True)\n",
    "#     encode_examples['target'] = tokenizer(targets, max_length=100, truncation=True, padding=True)\n",
    "    \n",
    "#     return encode_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e819f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    encode_examples = {}\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for doc in examples:\n",
    "        for dialog in doc['source']:\n",
    "            inputs.append(dialog)\n",
    "        for dialog in doc['target']: \n",
    "            targets.append(dialog)\n",
    "            \n",
    "    # inputs = [doc[\"maintext\"] for doc in examples]\n",
    "    encode_examples['source']  = tokenizer(inputs, max_length=200, truncation=True, padding=True)\n",
    "    encode_examples['target'] = tokenizer(targets, max_length=64, truncation=True, padding=True)\n",
    "    return encode_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cff6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_summerize = {}\n",
    "tokenized_set = preprocess_function(train_data)\n",
    "#tokenized_summerize['validation'] = preprocess_function(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5adf7508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639112\n",
      "1594153\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_set['target']['input_ids']))\n",
    "print(len(tokenized_set['source']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50de08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98406ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dialog(Dataset):\n",
    "    def __init__(self, encoded_dataset):\n",
    "        self.token = encoded_dataset['input_ids']\n",
    "        self.label = encoded_dataset['target']['input_ids'] if 'target' in encoded_dataset.keys() else None\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is None:\n",
    "            return torch.tensor(self.token[index])\n",
    "        else:\n",
    "            return torch.tensor(self.token[index]), torch.tensor(self.label[index])\n",
    "    def __len__(self):\n",
    "        return len(self.token)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23615d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dialog(tokenized_set)\n",
    "#valset = Dialog(tokenized_summerize['validation'])\n",
    "trainloader = DataLoader(dataset = trainset, batch_size = 64, shuffle = True)\n",
    "#valloader = DataLoader(dataset = valset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36364911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    #torch.save(model.state_dict(), checkpoint_path)\n",
    "    model.save_pretrained(checkpoint_path)\n",
    "    tokenizer.save_pretrained(checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    model = torch.load(checkpoint_path)\n",
    "    #model.load_state_dict(state['state_dict'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f63ac116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge_list = []\n",
    "# def test(model):\n",
    "#     model.eval()\n",
    "#     label_list,eval_predictions = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for i,(inputs_ids, labels) in enumerate(valloader):\n",
    "#             if i%170 == 0 and i != 0:\n",
    "#                 print(f\"---start evaluation---\")\n",
    "#             inputs_ids, labels = inputs_ids.to(device), labels.to(device)\n",
    "#             outputs = model.generate(inputs_ids,num_beams=5,max_length=64)\n",
    "#             eval_predictions  += outputs\n",
    "#             label_list += labels\n",
    "#         rouge = compute_metrics(eval_predictions, label_list)\n",
    "#         print(rouge)\n",
    "#         rouge_list.append(rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b912b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(model, epoch, save_interval, log_interval=100):\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=1e-4, betas=(0.9, 0.999),weight_decay=0)\n",
    "    model.train()  # set training mode\n",
    "    best = 0    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        loss_sum = 0\n",
    "        for batch_idx, (input_ids, labels) in enumerate(trainloader):\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_ids=input_ids,labels=labels)\n",
    "            loss = output.loss\n",
    "            loss_sum = loss_sum + loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(input_ids), len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                # test(model)\n",
    "                if iteration>500:\n",
    "                    save_checkpoint('./summary-%i/' % iteration, model, optimizer)    \n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "        print('\\nTrain set:Loss: ({:.0f})\\n'.format(loss_sum / len(trainloader)))\n",
    "        \n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('./summary-%i/' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a342d3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5bcda3b5fc45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a47e1abfd7ea>\u001b[0m in \u001b[0;36mtrain_save\u001b[0;34m(model, epoch, save_interval, log_interval)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-802d9bbe443f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_save(model, epoch = 8, save_interval = 500, log_interval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64360c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fa0578c3d0ab8305ee21e0a4f0a06849b2568e8436229705a3cd15e2e123ffa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
